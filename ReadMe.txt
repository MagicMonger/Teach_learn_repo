ReadMe
V 1.0
10/04/2025

К нам обратился магазин "В один клик" за помощью в удержании клиентов. Магазин занимается различными бытовыми и электронными товарами. В последнее время снизилась активность клиентов. Клиент уже проделал определенную работу, промаркировал клиентов классами покупательской активности, Не изменилось, Снизилась. Это очень хорошо и поможет нам в работе.

Наша задача состояла в том, чтобы из полученных данных построить модель, которая бы предсказывала статус клиента в течение трех месяцев, будет ли у клиента оставаться интерес к компании или же он начнет снижаться и компания рискует потерять клиента вовсе.

Проделана следующая работа:

- *После общего осмотра данных*, мы произвели их обработку. 

- *Статистическое исследование*. Для каждого столбца каждого датафрейма были найдены среднее, медиана, дисперсия, стандартное отклонение, межквартильный размах, минимальные и максимальные значения, их разность.

- *Корреляционный анализ*. Построена матрица корреляции Спирмана и Фи корреляции. 

Следующий шаг - *создание пайплайнов* и поиск лучшей модели.

Был построен пайплайн, и произведен поиск среди четырех моделей. Целевой признак Покупательская активность. Остальные признаки входные.

На вход пайплана подавались следующие модели и диапазоны их параметров:
- KNeighborsClassifier(n_neighbors=range(1, 7));
- DecisionTreeClassifier(max_depth=range(2, 6), max_features=range(2, 5));
- LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', penalty='l1');
- SVC(kernel='poly', random_state=RANDOM_STATE).

Разбиты на группы признаки, собраны в словари: ohe, ord, num. Для каждого обработчика своя категория.

Кодировка в пайплайне осуществлялась с помощью двух кодировщиков: OneHotEncoder и OrdinalEncoder. Первый задействован для кодировки бинарных значений, имеющих в столбцах всего по два строковых значения. Второй был примененм к столбцу Категория товаров. Так как категорий там 6, этот кодировщик лучше подходит.

Масштабирование в пайплайне сделано с помощью двух скэйлеров: StandartScaler() и MinMaxScaler(). Количественных признаков всего два.

В целом, в пайплане проделана следующая работа:
 - Присвоение целевого и входных признаков переменным у и Х;
 - Разбитие датафрейма на 4 выборки, входная тренировочная, входная тестовая, целевая тренировочная, целевая тестовая;
 - Кодирование категориальных признаков;
 - Масштабирование количественных;
 - Сборка столбцов и обработчиков с помощью трансформатора ColumnTransformer;
 - Создание итогового пайплана, куда включаются предподготовительные данные и трансформатор;

Затем мы осуществили поиск лучшей модели с помощью RandomizedSearchCV(). 
Лучшей моделью оказалась LogisticRegression(random_state=RANDOM_STATE, solver='liblinear', penalty='l1', С=4).

С помощью метрик мы определили следующую точность модели:

Метрика precision на тестовой выборке: 90%
Метрика recall на тестовой выборке: 95%
Метрика accuracy на тестовой выборке: 90%

Самый большой результат показала метрика recall.

Модель была обучена на тестовых данных.

Последним шагом в данном разделе было прогнозирование на реальном датасете. Выявлены пользователи с потенциальными статусами в течение трех месяцев. Мы добавили еще один столбцев в датафрейм, куда добавили спрогнозированные данные.

В *анализе важности признаков*, использовались значения Шепли, оценка которых производилась с помощью метода SHAP. Мы использовали три различных графика, каждый из которых показывал определенную сторону вклада признаков. Везде рассматривали 5ый объект. На первой диаграмме видно, что Страниц за визит, Средний просмотро категорий за визит и время на сайте являются наиболее весомыми в определеннии прогноза модели. 
Не имеют влияния на прогнозирование такие признаки как Тип Сервиса, Разрешение сообщать.

В *финальном шаге сегментации пользователей*, мы добавили четвертый датасет к общему.

*Сформировали предложение для компании*, как удержать эту категорию пользователей. 

V 1.01
- Для поиска лучшей модели убрана из поиска Логистическая регрессия.

V 1.02
- Изменены гиперпараметры следующих моделей:

- KNeighborsClassifier(n_neighbors=range(2, 9));
- DecisionTreeClassifier(max_depth=range(3, 8), max_features=range(2, 5));